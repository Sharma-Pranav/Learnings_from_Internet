{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLinBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, expansion_factor, identity_downsample= None) -> None:\n",
    "        \"\"\"\n",
    "        Residual Linear Block for neural networks.\n",
    "\n",
    "        Args:\n",
    "            in_features (int): Number of input features.\n",
    "            out_features (int): Number of output features.\n",
    "            expansion_factor (int): Expansion factor for output features.\n",
    "            identity_downsample (nn.Module, optional): Module for downsampling the identity (default: None).\n",
    "\n",
    "        Attributes:\n",
    "            in_features (int): Number of input features.\n",
    "            out_features (int): Number of output features.\n",
    "            expansion_factor (int): Expansion factor for output features.\n",
    "            identity_downsample (nn.Module): Module for downsampling the identity.\n",
    "            relu (ReLU): ReLU activation function.\n",
    "            lin_block (Sequential): Linear block consisting of multiple linear layers and batch normalization.\n",
    "            mapping_layer (Linear): Linear layer for feature mapping.\n",
    "        \"\"\"\n",
    "        super(ResLinBlock, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.expansion_factor = expansion_factor\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin_block = nn.Sequential(\n",
    "            # 1\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #2\n",
    "            nn.Linear(out_features,out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #3\n",
    "            nn.Linear(out_features, out_features*self.expansion_factor),\n",
    "            nn.BatchNorm1d(out_features*self.expansion_factor),\n",
    "            )\n",
    "        self.mapping_layer = nn.Linear(out_features*self.expansion_factor, out_features)\n",
    "    \n",
    "    def forward(self, x ):\n",
    "        \"\"\"\n",
    "        Forward pass of the Residual Linear Block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        identity = x.clone()\n",
    "        x = self.lin_block(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "  \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        if self.in_features!=self.out_features:\n",
    "            x = self.relu(self.mapping_layer(x))\n",
    "            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "in_channels = 3\n",
    "out_channels = 3\n",
    "expansion_factor = 4\n",
    "identity_downsample = nn.Sequential(nn.Linear(in_channels, out_channels*expansion_factor)\n",
    "                                                )\n",
    "def test():\n",
    "    \"\"\"\n",
    "    Test function for ResLinBlock.\n",
    "\n",
    "    This function creates an instance of ResLinBlock and tests it with random input data.\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    net = ResLinBlock(in_channels, out_channels, expansion_factor, identity_downsample= identity_downsample)\n",
    "    x = torch.randn(2,in_channels)\n",
    "    y = net(x)\n",
    "    print(y.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLinNet(nn.Module):\n",
    "    def __init__(self, in_features = 150, depths = [64, 64, 128, 128, 256], expansion_factor = 4, outputs = 1) -> None:\n",
    "        \"\"\"\n",
    "        Residual Linear Network constructor.\n",
    "\n",
    "        Args:\n",
    "        - in_features (int): Number of input features.\n",
    "        - depths (list): List of integers representing the number of features in each layer.\n",
    "        - expansion_factor (int): Expansion factor for linear layers.\n",
    "        - outputs (int): Number of output features.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(ResLinNet, self).__init__()\n",
    "        self.depths = depths\n",
    "        self.expansion_factor = expansion_factor\n",
    "        self.in_features = in_features\n",
    "        self.in_layer = nn.Linear(in_features, self.depths[0])\n",
    "        self.reslayers = nn.ModuleList([self.create_block(depths[i], depths[i+1]) for i in range(len(depths)-1)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_layer = nn.Linear(512, outputs)\n",
    "    def create_block(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        Create a Residual Linear Block.\n",
    "\n",
    "        Args:\n",
    "        - in_features (int): Number of input features.\n",
    "        - out_features (int): Number of output features.\n",
    "\n",
    "        Returns:\n",
    "        - block (ResLinBlock): Residual Linear Block instance.\n",
    "        \"\"\"\n",
    "        if in_features==out_features:\n",
    "            identity_downsample = None \n",
    "            layer_expansion_factor = 1  \n",
    "        else:\n",
    "            identity_downsample = nn.Sequential(nn.Linear(in_features, out_features*self.expansion_factor ))\n",
    "            layer_expansion_factor = self.expansion_factor\n",
    "\n",
    "            \n",
    "        return ResLinBlock(in_features, out_features, expansion_factor=layer_expansion_factor, identity_downsample=identity_downsample)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the Residual Linear Network.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - out (Tensor): Output tensor.\n",
    "        \"\"\"\n",
    "        x = self.relu(self.in_layer(x))\n",
    "        for i, layer in enumerate(self.reslayers):\n",
    "            x = layer(x)\n",
    "            \n",
    "        \n",
    "        flattened_tensor = torch.flatten(x)\n",
    "        out = self.relu(self.out_layer(flattened_tensor))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = ResLinNet()\n",
    "    x = torch.randn(2,150)\n",
    "    y = net(x)\n",
    "    print(y.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
